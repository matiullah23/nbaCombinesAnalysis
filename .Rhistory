install.packages("tidyr")
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
plot(x)
View(x)
x[1:25,1]=x[1:25,1]+3
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
plot(x)
x[1:25,1]=x[1:25,1]+3
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
plot(x)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
set.seed(2)
x=matrix(rnorm(50*2),ncol=2)
plot(x)
x[1:25,1]=x[1:25,1]+3
x[1:25,2]=x[1:25,2]-4
source('/Users/Matiullah/Desktop/nbaCombinesAnalysis/nba_combine_analysis.R', echo=TRUE)
#read in csv's
data2012 <- read.csv(file="2012_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2013 <- read.csv(file="2013_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2014 <- read.csv(file="2014_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2015 <- read.csv(file="2015_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2016 <- read.csv(file="2016_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#load libraries
library(data.table)
#combine the 4 datasets to create working dataset containing data for all 4 yeears
dataset <- rbind(data2012, data2013, data2014, data2015, data2016)
#drop the columns not being used (since these were not found in the other source of data for other combine years)
dataset <- dataset[,-1]
dataset <- dataset[,-9]
dataset <- dataset[,-9]
#bring in the data that was manually scraped from nba.com
rest_of_data <- read.csv(file="2001to2011_2017_2018_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#combine the two datasets to create master dataset
df <- rbind(dataset, rest_of_data)
#rename columns
setnames(df, old=c("Height (No Shoes)","Standing reach", "Weight", "Hand (Width)", "Sprint", "Height (With Shoes)", "Vertical (Max)", "Body Fat", "Bench", "Draft pick", "Wingspan", "Vertical (No Step Reach)", "Hand (Length)", "Agility"),
new=c("Height (inches, No Shoes)", "Standing Reach (inches)", "Weight (lbs)", "Hand Width (inches)", "Sprint (seconds)", "Height (With Shoes, inches)", "Vertical Max (inches)", "Body Fat (%)", "Bench Press (185lbs, repititions)", "Draft Pick", "Wingspan (inches)", "Vertical (No Step Reach, inches)", "Hand Length (inches)", "Agility (seconds)"))
#change data types of variables
str(df)
df$`Weight (lbs)` <- as.numeric(df$`Weight (lbs)`)
#export to CSV
write.csv(df, file="nba_combine_data_merged.csv", row.names=FALSE)
setwd("/Users/Matiullah/Desktop/nbaCombinesAnalysis")
source('/Users/Matiullah/Desktop/nbaCombinesAnalysis/nba_combine_analysis.R', echo=TRUE)
View(df)
plot(df$`Draft Pick`, df$`Height (inches, No Shoes)`)
abline(lm(df$`Draft Pick`, df$`Height (inches, No Shoes)`))
res <- cor(df)
round(res, 2)
res <- cor(df)
View(df)
str(df)
df2 <- df[-1]
df2 <- df2[-1]
str(df2)
res <- cor(df)
as.numeric(as.character(df2$`Draft Pick`))
str(df2)
as.data.frame(lapply(df2, as.numeric))
str(df2)
data <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#drop columns that are not needed
str(data)
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
View(data)
View(df)
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#drop columns that are not needed
str(df)
df <- data[-1]
df <- df[-1]
View(df)
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
df <- df[-1]
df <- df[-1]
View(df)
as.data.frame(lapply(df, as.numeric))
str(df)
transform(df, 'Draft Pick' = as.numeric('Draft Pick'))
str(df)
df <- transform(df, 'Draft Pick' = as.numeric('Draft Pick'))
str(df)
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#drop columns that are not needed
str(df)
df <- df[-1]
df <- df[-1]
View(df)
df[1] <- lapply(df[1], as.numeric)
str(df)
res <- cor(df)
round(res, 2)
res <- cor(df[1:5])
round(res, 2)
#remove columns of data with NA
df <- df[complete.cases(df), ]
res <- cor(df[1:5])
round(res, 2)
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#create a correlation matrix
#drop columns that are not needed
str(df)
df <- df[-1]
df <- df[-1]
df[1] <- lapply(df[1], as.numeric)
str(df)
#remove columns of data with NA
df <- df[complete.cases(df), ]
res <- cor(df)
round(res, 2)
correlations <- cor(df)
round(correlations, 2)
correlations <-round(correlations, 2)
View(correlations)
#read in csv's
data2012 <- read.csv(file="2012_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2013 <- read.csv(file="2013_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2014 <- read.csv(file="2014_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2015 <- read.csv(file="2015_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
data2016 <- read.csv(file="2016_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#load libraries
library(data.table)
#combine the 4 datasets to create working dataset containing data for all 4 years
dataset <- rbind(data2012, data2013, data2014, data2015, data2016)
#drop the columns not being used (since these were not found in the other source of data for other combine years)
dataset <- dataset[,-1]
dataset <- dataset[,-9]
dataset <- dataset[,-9]
#bring in the data that was manually scraped from nba.com
rest_of_data <- read.csv(file="2001to2011_2017_2018_nba_draft_combine.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#combine the two datasets to create master dataset
df <- rbind(dataset, rest_of_data)
#rename columns
setnames(df, old=c("Height (No Shoes)","Standing reach", "Weight", "Hand (Width)", "Sprint", "Height (With Shoes)", "Vertical (Max)", "Body Fat", "Bench", "Draft pick", "Wingspan", "Vertical (No Step Reach)", "Hand (Length)", "Agility"),
new=c("Height (inches, No Shoes)", "Standing Reach (inches)", "Weight (lbs)", "Hand Width (inches)", "Sprint (seconds)", "Height (With Shoes, inches)", "Vertical Max (inches)", "Body Fat (%)", "Bench Press (185lbs, repititions)", "Draft Pick", "Wingspan (inches)", "Vertical (No Step Reach, inches)", "Hand Length (inches)", "Agility (seconds)"))
#change data types of variables
str(df)
df$`Weight (lbs)` <- as.numeric(df$`Weight (lbs)`)
#export to CSV
write.csv(df, file="nba_combine_data_merged.csv", row.names=FALSE)
View(df)
#create and view the correlation matrix
correlations <- cor(df)
#create a correlation matrix
#read in data to be used
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#drop columns that are not needed - player's name and the year they were drafted
df <- df[-1]
df <- df[-1]
#convert draft pick column from integer to numeric so it can be used in correlation matrix
df[1] <- lapply(df[1], as.numeric)
#remove columns of data with NA
df <- df[complete.cases(df), ]
#create and view the correlation matrix
correlations <- cor(df)
correlations <-round(correlations, 2)
View(correlations)
View(df)
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
View(df)
#keep only columns needed for this analysis
df <- df[2,10]
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#keep only columns needed for this analysis
df <- df[2,10]
#keep only columns needed for this analysis
df <- df[,c(2,10)]
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#keep only columns needed for this analysis
df <- df[,c(2,10)]
View(df)
#create a new column that finds the average weight of players in the combine in that year
avgWeightByYear <- aggregate(df$Year, by=list(df$`Weight (lbs)`), FUN=mean)[2]
View(avgWeightByYear)
#create a new column that finds the average weight of players in the combine in that year
avgWeightByYear <- aggregate(df$Year, by=list(df$`Weight (lbs)`), FUN=mean)
#create a new column that finds the average weight of players in the combine in that year
aggdata <- aggregate(df, by=list(Year), FUN = mean, na.rm=TRUE)
#create a new column that finds the average weight of players in the combine in that year
aggdata <- aggregate(df, by=df$Year), FUN = mean, na.rm=TRUE)
#create a new column that finds the average weight of players in the combine in that year
aggdata <- aggregate(df, by=df$Year, FUN = mean, na.rm=TRUE)
#create a new column that finds the average weight of players in the combine in that year
aggdata <- aggregate(df, by=list(df$Year), FUN = mean, na.rm=TRUE)
View(aggdata)
# find the average weight of players who were drafted prior to 2004-2005 rule change that lessened physical play
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#keep only columns needed for this analysis
df <- df[,c(2,10)]
#find the average weight of players in the combine in that year
df <- aggregate(df, by=list(df$Year), FUN = mean, na.rm=TRUE)
#drop the first column which is not needed
df <- df[-1]
View(df)
#round the weight
df <-round(df, 2)
View(df)
#round the weight
df <-round(df, 0)
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#keep only columns needed for this analysis
df <- df[,c(2,10)]
#remove NA as the focus is on drafted players for this analysis
df <- df[complete.cases(df), ]
#read in data
df <- read.csv(file="nba_combine_data_merged.csv", header=TRUE, sep=",", check.names = FALSE, fileEncoding = 'UTF-8-BOM')
#remove undrafted players
df <- df[complete.cases(df$`Draft Pick`), ]
#keep only columns needed for this analysis
df <- df[,c(2,10)]
#find the average weight of players in the combine in that year
df <- aggregate(df, by=list(df$Year), FUN = mean, na.rm=TRUE)
#drop the first column which is not needed
df <- df[-1]
#round the weight
df <-round(df, 0)
View(df)
#find the average of 2004 and prior and 2005 and after
setOne <- mean(df[1:5,2])
setTwo <- mean(df[6:,2])
setTwo <- mean(df[6:,,2])
setTwo <- mean(df[6:19,2])
setTwo <- round(mean(df[6:19,2]),0)
setTwo <- round(mean(df[6:19,2]),2)
#find the average of 2004 and prior and 2005 and after
setOne <- round(mean(df[1:5,2]),2)
source('~/.active-rstudio-document', echo=TRUE)
